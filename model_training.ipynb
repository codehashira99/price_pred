{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5cf0f9f3-9106-4287-8060-1fb3a4fc3f03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch: 2.9.1+cu128\n",
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "import os, json, numpy as np, pandas as pd, torch, torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models, transforms\n",
    "from torchvision.models import ResNet18_Weights\n",
    "from PIL import Image\n",
    "import joblib\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"PyTorch:\", torch.__version__)\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Device: {DEVICE}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "629f7dc1-9420-4d71-b02e-f56a1a7e1c72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Tabular: Train=(12901, 21), Val=(3226, 21)\n",
      "âœ… Images ready: data/images/train, data/images/test\n"
     ]
    }
   ],
   "source": [
    "PROCESSED_DIR = \"data/processed\"\n",
    "TRAIN_IMG_DIR = \"data/images/train\"\n",
    "TEST_IMG_DIR = \"data/images/test\"\n",
    "\n",
    "# Load tabular arrays\n",
    "X_train_tab = np.load(f\"{PROCESSED_DIR}/X_train_tabular.npy\")\n",
    "X_val_tab = np.load(f\"{PROCESSED_DIR}/X_val_tabular.npy\")\n",
    "y_train = np.load(f\"{PROCESSED_DIR}/y_train_log_price.npy\")\n",
    "y_val = np.load(f\"{PROCESSED_DIR}/y_val_log_price.npy\")\n",
    "train_ids = np.load(f\"{PROCESSED_DIR}/train_ids.npy\")\n",
    "val_ids = np.load(f\"{PROCESSED_DIR}/val_ids.npy\")\n",
    "\n",
    "scaler = joblib.load(f\"{PROCESSED_DIR}/tabular_scaler.joblib\")\n",
    "with open(f\"{PROCESSED_DIR}/metadata.json\") as f:\n",
    "    meta = json.load(f)\n",
    "\n",
    "print(f\"âœ… Tabular: Train={X_train_tab.shape}, Val={X_val_tab.shape}\")\n",
    "print(f\"âœ… Images ready: {TRAIN_IMG_DIR}, {TEST_IMG_DIR}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cef75d4d-9b6b-437a-b396-5d6e2a3cca7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Extracting train image features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting data/images/train: 100%|â–ˆ| 12901/12901 [05:09<00:00, 41.70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Extracting val image features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting data/images/train: 100%|â–ˆ| 3226/3226 [01:13<00:00, 43.81it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Image features saved!\n"
     ]
    }
   ],
   "source": [
    "# EXTRACT IMAGE FEATURES FROM FOLDER\n",
    "import torch\n",
    "from torchvision import models, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import joblib\n",
    "\n",
    "# Feature extractor (ResNet18 â†’ 512 features)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "backbone = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
    "backbone.fc = torch.nn.Identity()  # Remove classifier â†’ 512 features\n",
    "backbone = backbone.to(device).eval()\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485,0.456,0.406], [0.229,0.224,0.225])\n",
    "])\n",
    "\n",
    "def extract_features_from_folder(img_dir, ids):\n",
    "    \"\"\"Extract 512 features per image\"\"\"\n",
    "    features = {}\n",
    "    \n",
    "    for prop_id in tqdm(ids, desc=f\"Extracting {img_dir}\"):\n",
    "        img_path = os.path.join(img_dir, f\"{int(prop_id)}.png\")\n",
    "        \n",
    "        if os.path.exists(img_path):\n",
    "            img = Image.open(img_path).convert('RGB')\n",
    "            img_t = transform(img).unsqueeze(0).to(device)\n",
    "            with torch.no_grad():\n",
    "                feat = backbone(img_t).cpu().numpy().flatten()\n",
    "            features[str(prop_id)] = feat\n",
    "        else:\n",
    "            # Zero features for missing images\n",
    "            features[str(prop_id)] = np.zeros(512)\n",
    "    \n",
    "    return features\n",
    "\n",
    "print(\"ðŸ”„ Extracting train image features...\")\n",
    "train_img_features = extract_features_from_folder(TRAIN_IMG_DIR, train_ids)\n",
    "\n",
    "print(\"ðŸ”„ Extracting val image features...\")\n",
    "val_img_features = extract_features_from_folder(TRAIN_IMG_DIR, val_ids)\n",
    "\n",
    "# Save\n",
    "joblib.dump(train_img_features, f\"{PROCESSED_DIR}/train_img_features.pkl\")\n",
    "joblib.dump(val_img_features, f\"{PROCESSED_DIR}/val_img_features.pkl\")\n",
    "print(\"âœ… Image features saved!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae360d64-c1c0-4841-8cfd-8e1895c399f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ” VERIFY IMAGE FEATURES BEFORE COMBINING\n",
    "print(\"ðŸ” Verifying extracted image features...\")\n",
    "\n",
    "# Load your extracted features\n",
    "train_img_feat = joblib.load(f\"{PROCESSED_DIR}/train_img_features.pkl\")\n",
    "val_img_feat = joblib.load(f\"{PROCESSED_DIR}/val_img_features.pkl\")\n",
    "\n",
    "print(f\"Train images extracted: {len(train_img_feat)}\")\n",
    "print(f\"Val images extracted:   {len(val_img_feat)}\")\n",
    "\n",
    "# Check sample shapes\n",
    "sample_train_id = list(train_img_feat.keys())[0]\n",
    "sample_val_id = list(val_img_feat.keys())[0]\n",
    "\n",
    "print(f\"\\n Sample train ID {sample_train_id}: {train_img_feat[sample_train_id].shape}\")\n",
    "print(f\" Sample val ID   {sample_val_id}:   {val_img_feat[sample_val_id].shape}\")\n",
    "\n",
    "# Verify ALL are 512\n",
    "train_shapes = set(len(feat) for feat in train_img_feat.values())\n",
    "val_shapes = set(len(feat) for feat in val_img_feat.values())\n",
    "print(f\"\\n Train feature sizes: {train_shapes}\")  # {512}\n",
    "print(f\"Val feature sizes:   {val_shapes}\")    # {512}\n",
    "\n",
    "assert 512 in train_shapes and len(train_shapes) == 1, \"Train features not uniform 512!\"\n",
    "assert 512 in val_shapes and len(val_shapes) == 1, \"Val features not uniform 512!\"\n",
    "print(\"ALL FEATURES = 512 âœ“\")\n",
    "\n",
    "# Quick DataFrame preview (first 5 images)\n",
    "train_sample_df = pd.DataFrame.from_dict(\n",
    "    {k: v[:5] for k, v in list(train_img_feat.items())[:5]},  # first 5 features\n",
    "    orient=\"index\"\n",
    ")\n",
    "train_sample_df.columns = [f\"img_feat_{i}\" for i in range(5)]\n",
    "print(\"\\n Sample train features (first 5):\")\n",
    "print(train_sample_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9c11c9-34f4-4e8b-ac39-6a84987843e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸŸ¢ VERIFICATION PASSED â†’ COMBINE FEATURES\n",
    "print(\"\\n Combining tabular + 512 image features...\")\n",
    "\n",
    "# Convert dict to arrays (match ID order)\n",
    "train_img_array = np.array([train_img_feat[str(int(id))] for id in train_ids])\n",
    "val_img_array = np.array([val_img_feat[str(int(id))] for id in val_ids])\n",
    "\n",
    "# Stack: tabular + images\n",
    "X_train_full = np.hstack([X_train_tab, train_img_array])\n",
    "X_val_full = np.hstack([X_val_tab, val_img_array])\n",
    "\n",
    "print(f\"âœ… COMBINED FEATURES:\")\n",
    "print(f\"   Train shape: {X_train_full.shape} (tabular + 512 img)\")\n",
    "print(f\"   Val shape:   {X_val_full.shape}\")\n",
    "print(f\"   New feature count: {X_train_full.shape[1]}\")\n",
    "\n",
    "# Save combined\n",
    "np.save(f\"{PROCESSED_DIR}/X_train_full.npy\", X_train_full)\n",
    "np.save(f\"{PROCESSED_DIR}/X_val_full.npy\", X_val_full)\n",
    "print(\" Saved full features!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d6327b77-da42-48e6-a141-f046b815f902",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ FAST HISTOGRADIENTBOOSTING (2 min)\n",
      "Training fusion model...\n",
      "Binning 0.050 GB of training data: 0.301 s\n",
      "Binning 0.006 GB of validation data: 0.012 s\n",
      "Fitting gradient boosted rounds:\n",
      "Fit 110 trees in 3.162 s, (3410 total leaves)\n",
      "Time spent computing histograms: 1.568s\n",
      "Time spent finding best splits:  1.009s\n",
      "Time spent applying splits:      0.080s\n",
      "Time spent predicting:           0.006s\n",
      "âœ… Training complete!\n",
      "\n",
      "ðŸŽ¯ FUSION RESULTS:\n",
      "   Tabular RMSE: 101496\n",
      "   Fusion RMSE:  101420\n",
      "   Fusion RÂ²:    0.888\n",
      "   Improvement: 0.1%\n",
      "âœ… Model saved!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "\n",
    "\n",
    "# Ultra-fast histogram version\n",
    "fusion_model = HistGradientBoostingRegressor(\n",
    "    max_iter=500,           # 500 trees (vs 1000)\n",
    "    max_depth=10,           # Slightly deeper\n",
    "    learning_rate=0.08,\n",
    "    random_state=42,\n",
    "    verbose=1               # Progress bar\n",
    ")\n",
    "\n",
    "print(\"Training fusion model...\")\n",
    "fusion_model.fit(X_train_full, y_train)\n",
    "print(\" Training complete!\")\n",
    "\n",
    "# Results\n",
    "y_val_pred_log = fusion_model.predict(X_val_full)\n",
    "rmse = np.sqrt(mean_squared_error(np.expm1(y_val), np.expm1(y_val_pred_log)))\n",
    "r2 = r2_score(np.expm1(y_val), np.expm1(y_val_pred_log))\n",
    "\n",
    "print(f\"\\n FUSION RESULTS:\")\n",
    "print(f\"   Tabular RMSE: 101496\")\n",
    "print(f\"   Fusion RMSE:  {rmse:.0f}\")\n",
    "print(f\"   Fusion RÂ²:    {r2:.3f}\")\n",
    "print(f\"   Improvement: {(101496-rmse)/101496*100:.1f}%\")\n",
    "\n",
    "# Save\n",
    "import joblib\n",
    "joblib.dump(fusion_model, f\"{PROCESSED_DIR}/fusion_model.joblib\")\n",
    "print(\"Model saved!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b0569fb3-1a57-4c1a-8a40-4cc76954a264",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Creating test_img_features.pkl...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting data/images/test: 100%|â–ˆ| 5404/5404 [03:40<00:00, 24.47it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Test features saved: 5396 images\n"
     ]
    }
   ],
   "source": [
    "# ðŸ§ª MISSING TEST FEATURES â†’ CREATE NOW\n",
    "print(\"ðŸ”„ Creating test_img_features.pkl...\")\n",
    "\n",
    "test_df = pd.read_csv(\"data/test.csv\")\n",
    "test_ids = test_df[\"id\"].values\n",
    "\n",
    "# Use your existing backbone/transform\n",
    "test_img_features = extract_features_from_folder(TEST_IMG_DIR, test_ids)\n",
    "\n",
    "joblib.dump(test_img_features, f\"{PROCESSED_DIR}/test_img_features.pkl\")\n",
    "print(f\"âœ… Test features saved: {len(test_img_features)} images\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9542a583-c75f-4746-9826-693d79158eeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " submission.csv SAVED!\n",
      "Samples: 5404\n",
      "Prices:  $131299 - $2932170\n"
     ]
    }
   ],
   "source": [
    "# ðŸ† CORRECT FINAL SUBMISSION (creates all 21 features)\n",
    "import joblib, numpy as np, pandas as pd, json\n",
    "\n",
    "PROCESSED_DIR = \"data/processed\"\n",
    "\n",
    "# Load\n",
    "fusion_model = joblib.load(PROCESSED_DIR + \"/fusion_model.joblib\")\n",
    "scaler = joblib.load(PROCESSED_DIR + \"/tabular_scaler.joblib\")\n",
    "with open(PROCESSED_DIR + \"/metadata.json\", \"r\") as f:\n",
    "    meta = json.load(f)\n",
    "test_img_features = joblib.load(PROCESSED_DIR + \"/test_img_features.pkl\")\n",
    "test_df = pd.read_csv(\"data/test.csv\")\n",
    "\n",
    "# ðŸ”¥ CREATE ALL 21 EXPECTED FEATURES\n",
    "expected_features = meta[\"numeric_features\"]  # 21 features\n",
    "\n",
    "\n",
    "# Create DataFrame with ALL expected columns (missing = 0)\n",
    "test_features_df = pd.DataFrame(0, index=test_df.index, columns=expected_features)\n",
    "test_features_df[\"id\"] = test_df[\"id\"]  # Keep ID\n",
    "\n",
    "# Fill available features from test.csv\n",
    "for col in expected_features:\n",
    "    if col in test_df.columns:\n",
    "        test_features_df[col] = test_df[col].fillna(0)\n",
    "\n",
    "\n",
    "\n",
    "# Transform ALL 21 features\n",
    "test_tabular = scaler.transform(test_features_df[expected_features].values)\n",
    "\n",
    "\n",
    "# Image features\n",
    "test_img_array = np.array([test_img_features.get(str(int(id)), np.zeros(512)) for id in test_df[\"id\"]])\n",
    "\n",
    "# Combine & predict\n",
    "X_test = np.column_stack([test_tabular, test_img_array])\n",
    "test_prices = np.expm1(fusion_model.predict(X_test))\n",
    "\n",
    "# Save\n",
    "pd.DataFrame({\n",
    "    \"id\": test_df[\"id\"].astype(int),\n",
    "    \"predicted_price\": test_prices\n",
    "}).to_csv(\"submission.csv\", index=False)\n",
    "\n",
    "print(\"\\n submission.csv SAVED!\")\n",
    "print(f\"Samples: {len(test_prices)}\")\n",
    "print(f\"Prices:  ${test_prices.min():.0f} - ${test_prices.max():.0f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6872fc1e-d7b8-496b-8e1c-91da5d061566",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
